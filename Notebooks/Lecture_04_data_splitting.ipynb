{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can follow along and play with this notebook by clicking the badge below\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jasongfleischer/UCSD_COGS118A/blob/main/Notebooks/Lecture_04_data_splitting.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting - intuition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import ShuffleSplit, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# some utility functions to create toy data\n",
    "# data ~ underlying function + gaussian noise\n",
    "\n",
    "def create_toy_data(func, sample_size, std):\n",
    "    x = np.linspace(0, 1, sample_size).reshape(-1, 1)\n",
    "    t = func(x) + np.random.normal(scale=std, size=x.shape)\n",
    "    return x, t\n",
    "\n",
    "def a_sinusoidal_func(x):\n",
    "    return np.sin(2 * np.pi * x)\n",
    "\n",
    "def a_polynomial_func(x):\n",
    "    return (12. + 6.14*x - 8.4*x*x)\n",
    "\n",
    "def an_exp_func(x):\n",
    "    return (1+1*np.exp(0.001*x))\n",
    "\n",
    "def a_linear_func(x):\n",
    "    return (1.17 + 3.14*x)\n",
    "\n",
    "def a_discontinuous_func(x):\n",
    "    return [ 1. if el>0.5 else 0. for el in x  ]\n",
    "    \n",
    "sample_size = 10\n",
    "sigma = 0.5\n",
    "\n",
    "#func = a_sinusoidal_func\n",
    "#func = a_polynomial_func\n",
    "#func = a_discontinuous_func\n",
    "func = a_linear_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see what happens when we take many draws of data generated by the same linear function + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "x_train, y_train = create_toy_data(func, sample_size, sigma)\n",
    "x_predict = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_true = func(x_predict)\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "feature = PolynomialFeatures(degree=1)\n",
    "X_train = feature.fit_transform(x_train)\n",
    "X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\")\n",
    "\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8675309)\n",
    "x_train, y_train = create_toy_data(func, sample_size, sigma)\n",
    "x_predict = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_true = func(x_predict)\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "feature = PolynomialFeatures(degree=1)\n",
    "X_train = feature.fit_transform(x_train)\n",
    "X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\")\n",
    "\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x_train, y_train = create_toy_data(func, sample_size, sigma)\n",
    "x_predict = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_true = func(x_predict)\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "feature = PolynomialFeatures(degree=1)\n",
    "X_train = feature.fit_transform(x_train)\n",
    "X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\")\n",
    "\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "x_train, y_train = create_toy_data(func, sample_size, sigma)\n",
    "x_predict = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_true = func(x_predict)\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "feature = PolynomialFeatures(degree=1)\n",
    "X_train = feature.fit_transform(x_train)\n",
    "X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\")\n",
    "\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2001)\n",
    "x_train, y_train = create_toy_data(func, sample_size, sigma)\n",
    "x_predict = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_true = func(x_predict)\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "feature = PolynomialFeatures(degree=1)\n",
    "X_train = feature.fit_transform(x_train)\n",
    "X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\")\n",
    "\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmmm...\n",
    "So different draws of the same random process produce similar - yet - different results\n",
    "\n",
    "# Logically we expect the same thing to happen when we draw a larger dataset once, and take different random splits from it\n",
    "\n",
    " So let's draw 10 times as many data points a before... and then split them up into 10 non-overlapping folds of data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2001)\n",
    "sample_size = 100 # 10x number of samples as before\n",
    "\n",
    "x_all, y_all = create_toy_data(func, sample_size, sigma)\n",
    "x_predict = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_true = func(x_predict)\n",
    "\n",
    "\n",
    "plt.scatter(x_all, y_all, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "plt.title('All our data')\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random shuffling of the #s 0 to 99\n",
    "shuffled_indices = np.arange(0,100)\n",
    "np.random.shuffle( shuffled_indices )\n",
    "print(shuffled_indices)\n",
    "\n",
    "print('we will split our shuffled data indices into 10 equal groups, 0-9; 10-19; ...')\n",
    "for start in np.arange(0,99,10):\n",
    "    stop = start + 10\n",
    "    print(start,stop,'\\t',shuffled_indices[start:stop])\n",
    "    \n",
    "# OK lets make some shuffled data\n",
    "x_all_shuff = x_all[shuffled_indices]\n",
    "y_all_shuff = y_all[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we will plot 10 random draws of 10 training points from the bigger 100 point dataset\n",
    "# and also the resulting lines of regression\n",
    "for start in np.arange(0,99,10):\n",
    "    stop = start + 10\n",
    "    x_train = x_all_shuff[start:stop]\n",
    "    y_train = y_all_shuff[start:stop]\n",
    "    \n",
    "    plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "    plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "    feature = PolynomialFeatures(degree=1)\n",
    "    X_train = feature.fit_transform(x_train)\n",
    "    X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_predict)\n",
    "\n",
    "    plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\")\n",
    "\n",
    "    plt.ylim(bottom=0.0)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we will plot just he resulting lines of regression on top of each other in red\n",
    "# and the true line generating in green\n",
    "skip = 10\n",
    "for start in np.arange(0,99,skip):\n",
    "    stop = start + skip\n",
    "    x_train = x_all_shuff[start:stop]\n",
    "    y_train = y_all_shuff[start:stop]\n",
    "    \n",
    "    #plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "    #plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "    feature = PolynomialFeatures(degree=1)\n",
    "    X_train = feature.fit_transform(x_train)\n",
    "    X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_predict)\n",
    "\n",
    "    plt.plot(x_predict, y_predict, c=\"r\", label=\"fitted line\", alpha=0.5)\n",
    "\n",
    "    plt.ylim(bottom=0.0)\n",
    "\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we will plot just he resulting lines of regression on top of each other in red\n",
    "# and the true line generating in green\n",
    "# and the mean of all the coeficients we came up with in cyan\n",
    "coefs = []\n",
    "skip = 10\n",
    "for start in np.arange(0,99,skip):\n",
    "    stop = start + skip\n",
    "    x_train = x_all_shuff[start:stop]\n",
    "    y_train = y_all_shuff[start:stop]\n",
    "    \n",
    "    #plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "    #plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "    feature = PolynomialFeatures(degree=1)\n",
    "    X_train = feature.fit_transform(x_train)\n",
    "    X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    coefs.append( model.coef_ )\n",
    "    y_predict = model.predict(X_predict)\n",
    "\n",
    "    plt.plot(x_predict, y_predict, c=\"r\", alpha=0.2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "coefs = np.array(coefs)\n",
    "mean_coef = np.mean( np.squeeze(coefs), 0)\n",
    "model.coef_ = mean_coef\n",
    "y_predict_mean = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"c\", label=\"fitted line of mean coefficients\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.title('10 folds of 10 samples each')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we will plot just he resulting lines of regression on top of each other in red\n",
    "# and the true line generating in green\n",
    "# and the mean of all the coeficients we came up with in cyan\n",
    "coefs = []\n",
    "skip = 5\n",
    "for start in np.arange(0,99,skip):\n",
    "    stop = start + skip\n",
    "    x_train = x_all_shuff[start:stop]\n",
    "    y_train = y_all_shuff[start:stop]\n",
    "    \n",
    "    #plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "    #plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "    feature = PolynomialFeatures(degree=1)\n",
    "    X_train = feature.fit_transform(x_train)\n",
    "    X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    coefs.append( model.coef_ )\n",
    "    y_predict = model.predict(X_predict)\n",
    "\n",
    "    plt.plot(x_predict, y_predict, c=\"r\", alpha=0.2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "coefs = np.array(coefs)\n",
    "mean_coef = np.mean( np.squeeze(coefs), 0)\n",
    "model.coef_ = mean_coef\n",
    "y_predict_mean = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"c\", label=\"fitted line of mean coefficients\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "plt.ylim(bottom=0.0, top=4.88)\n",
    "plt.title('20 folds of 5 samples each')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we will plot just he resulting lines of regression on top of each other in red\n",
    "# and the true line generating in green\n",
    "# and the mean of all the coeficients we came up with in cyan\n",
    "coefs = []\n",
    "skip = 20\n",
    "for start in np.arange(0,99,skip):\n",
    "    stop = start + skip\n",
    "    x_train = x_all_shuff[start:stop]\n",
    "    y_train = y_all_shuff[start:stop]\n",
    "    \n",
    "    #plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "    #plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "\n",
    "    feature = PolynomialFeatures(degree=1)\n",
    "    X_train = feature.fit_transform(x_train)\n",
    "    X_predict = feature.fit_transform(x_predict)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    coefs.append( model.coef_ )\n",
    "    y_predict = model.predict(X_predict)\n",
    "\n",
    "    plt.plot(x_predict, y_predict, c=\"r\", alpha=0.35)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "coefs = np.array(coefs)\n",
    "mean_coef = np.mean( np.squeeze(coefs), 0)\n",
    "model.coef_ = mean_coef\n",
    "y_predict_mean = model.predict(X_predict)\n",
    "\n",
    "plt.plot(x_predict, y_predict, c=\"c\", label=\"fitted line of mean coefficients\")\n",
    "plt.plot(x_predict, y_true, c=\"g\", label=\"generating function\")\n",
    "plt.ylim(bottom=0.0,top=4.88)\n",
    "plt.title('5 folds of 20 samples each')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "-------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use a training set and a test set, and take a look at the Mean Squared Error of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "sample_size = 50 \n",
    "sigma = 0.5\n",
    "\n",
    "x_all, y_all = create_toy_data(func, sample_size, sigma)\n",
    "x_generating = np.linspace(0, 1, 100).reshape(-1, 1) #  some x-vals so we can generate true y-vals\n",
    "y_generating = func(x_generating)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( x_all, y_all, test_size=0.33)\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.scatter(x_test, y_test, facecolor=\"none\", edgecolor=\"y\", s=50, label=\"test data\");\n",
    "plt.plot(x_generating, y_generating, c=\"g\", label=\"generating function\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = PolynomialFeatures(degree=1)\n",
    "X_train = feature.fit_transform(x_train)\n",
    "X_predict = feature.fit_transform(x_predict)\n",
    "X_test = feature.fit_transform(x_test)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_regr = model.predict(X_predict) # this is the line of regression\n",
    "\n",
    "# these are the predictions (yhat) once the model is fitted on training and test sets\n",
    "# the difference between predicted_train and y_train is the training set error \n",
    "predicted_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "#plt.scatter(x_test, y_test, facecolor=\"none\", edgecolor=\"y\", s=50, label=\"test data\");\n",
    "plt.plot(x_generating, y_generating, c=\"g\", label=\"generating function\")\n",
    "plt.plot(x_generating, y_regr, c=\"r\", label=\"fitted line\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Training set error (MSE):', mean_squared_error(y_train,predicted_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the difference between predicted_test and y_test is the test set error \n",
    "predicted_test = model.predict(X_test) \n",
    "\n",
    "#plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.scatter(x_test, y_test, facecolor=\"none\", edgecolor=\"y\", s=50, label=\"test data\");\n",
    "plt.plot(x_generating, y_generating, c=\"g\", label=\"generating function\")\n",
    "plt.plot(x_generating, y_regr, c=\"r\", label=\"fitted line from training data\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Test set error (MSE):', mean_squared_error(y_test,predicted_test))\n",
    "print('We are predicting this as a measure of how our function will do when it generalizes to new data points from teh same underlying process')\n",
    "print('Compare me to the value for a 10k new sample above, which is a better idea of the true generalizaiton')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to verify lets draw a bunch of brand new data and see how it does...\n",
    "\n",
    "x_new, y_new = create_toy_data(func, 10000, sigma)\n",
    "X_new = feature.fit_transform(x_new)\n",
    "predicted_new = model.predict(X_new) \n",
    "print('Generalization with new dataset error (MSE)', mean_squared_error(y_new,predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, let's use a 5-fold cross-validation to estimate generalization performance\n",
    "# we use all the data to make the folds of the cross-validation\n",
    "\n",
    "X_all = feature.fit_transform(x_all)\n",
    "\n",
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "# collect the predicted y values and true y values of each hold out set\n",
    "predicteds=[]\n",
    "trueys=[]\n",
    "for train, holdout in k_fold.split(X_all, y_all):\n",
    "    model.fit(X_all[train],y_all[train])\n",
    "    predicteds.append( model.predict(X_all[holdout]) )\n",
    "    trueys.append( y_all[holdout] )\n",
    "\n",
    "# this is because we ended up with a list of arrays, we need a flat array\n",
    "predicteds = np.array(predicteds).flatten()\n",
    "trueys = np.array(trueys).flatten()\n",
    "\n",
    "print('5-fold cross validation error (MSE)', mean_squared_error(trueys,predicteds))\n",
    "print('Compare me to the value for a 10k new sample above, which is a better idea of the true generalizaiton')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
